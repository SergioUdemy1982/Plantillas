scale_shape_manual(values = shapes)
rlang::last_error()
ggplot() +
geom_tile(data = grid_set_testing,
mapping = aes(x = Age,
y = EstimatedSalary,
fill = y_grid_testing))
View(grid_set_testing)
plot(set_testing[, -3],
main = 'SVM (Test set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1_testing),
ylim = range(X2_testing))
contour(X1_testing,
X2_testing,
matrix(as.numeric(y_grid_testing),
length(X1_testing),
length(X2_testing)),
add = TRUE)
points(grid_set_testing,
pch = '.',
col = ifelse(y_grid_testing == 1, "#00BFC4", "#F8766D"))
points(set_testing,
pch = 21,
bg = ifelse(set_testing[, 3] == 1, 'green4', 'red3'))
set_testing = testing
X1_testing = seq(min(set_testing[, 1]) - 1, max(set_testing[, 1]) + 1, by = 0.01)
X2_testing = seq(min(set_testing[, 2]) - 1, max(set_testing[, 2]) + 1, by = 0.01)
grid_set_testing = expand.grid(X1_testing, X2_testing)
colnames(grid_set_testing) = c('Age', 'EstimatedSalary')
y_grid_testing = predict(object = classifier, newdata = grid_set_testing)
plot(set_testing[, -3],
main = 'SVM (Test set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1_testing),
ylim = range(X2_testing))
contour(X1_testing,
X2_testing,
matrix(as.numeric(y_grid_testing),
length(X1_testing),
length(X2_testing)),
add = TRUE)
points(grid_set_testing,
pch = '.',
col = ifelse(y_grid_testing == 1, "#00BFC4", "#F8766D"))
points(set_testing,
pch = 21,
bg = ifelse(set_testing[, 3] == 1, 'green4', 'red3'))
dataset = read_csv(file = "Datasets/Social_Network_Ads.csv")
#View(dataset)
#glimpse(dataset)
dataset %>%
select(c(-1,-2)) -> dataset
# Codificacion de la variable respuesta como factor
dataset$Purchased <- factor(x = dataset$Purchased, levels = c(0,1))
# Separacion de dataset en Training y Testing
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training = subset(dataset, split == TRUE)
testing = subset(dataset, split == FALSE)
# Escalado
training[, 1:2] = scale(training[, 1:2])
testing[, 1:2] = scale(testing[, 1:2])
# Modelo
classifier <- glm(formula = Purchased ~ .,
data = training,
family = binomial)
#summary(classifier)
# Predicciones
# Probabilidades
prob_pred <- predict(object = classifier,
type = "response",
newdata = testing[, 1:2])
# Predicciones con umbral de 0.5
y_pred <- ifelse(prob_pred > 0.5, 1, 0)
testing %>%
mutate(Preds = y_pred,
Probs = prob_pred) -> modelo
#View(modelo)
# Matriz de confusion para revisar predicciones correctas
cm = table(Real = modelo$Purchased, Predict = modelo$Preds)
cm
#    Predict
#Real  0  1
#   0 57  7
#   1 10 26
sum(diag(cm))  # 83 predicciones correctas
sum(diag(apply(cm,2,rev))) # 17 predicciones incorrectas
set_testing = testing
X1_testing = seq(min(set_testing[, 1]) - 1, max(set_testing[, 1]) + 1, by = 0.01)
X2_testing = seq(min(set_testing[, 2]) - 1, max(set_testing[, 2]) + 1, by = 0.01)
grid_set_testing = expand.grid(X1_testing, X2_testing)
colnames(grid_set_testing) = c('Age', 'EstimatedSalary')
y_grid_testing = predict(object = classifier, newdata = grid_set_testing)
plot(set_testing[, -3],
main = 'Logistic Regression (Test set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1_testing),
ylim = range(X2_testing))
contour(X1_testing,
X2_testing,
matrix(as.numeric(y_grid_testing),
length(X1_testing),
length(X2_testing)),
add = TRUE)
points(grid_set_testing,
pch = '.',
col = ifelse(y_grid_testing == 1, "#00BFC4", "#F8766D"))
points(set_testing,
pch = 21,
bg = ifelse(set_testing[, 3] == 1, 'green4', 'red3'))
cols <- c('Red' = 'red', 'Green' = 'green')
shapes <- c('No' = 4, 'Yes' = 1)
ggplot() +
geom_tile(data = grid_set_testing,
mapping = aes(x = Age,
y = EstimatedSalary,
fill = y_grid_testing)) +
geom_point(data = modelo,
mapping = aes(x = Age,
y = EstimatedSalary,
shape = shapes),
size = 3) +
labs(title = "Logistic Regression Predictions",
subtitle = "Predictions: 87 correct | 13 Incorrect",
fill = "Purchase",
shape = "Support",
color = "Color") +
scale_color_manual(values = cols) +
scale_shape_manual(values = shapes)
View(modelo)
modelo %>%
mutate(Correct = ifelse(Purchased == Preds, "Yes", "No")) -> modelo
cols <- c('Red' = 'red', 'Green' = 'green')
shapes <- c('No' = 4, 'Yes' = 1)
ggplot() +
geom_tile(data = grid_set_testing,
mapping = aes(x = Age,
y = EstimatedSalary,
fill = y_grid_testing)) +
geom_point(data = modelo,
mapping = aes(x = Age,
y = EstimatedSalary,
shape = Correct),
size = 3) +
labs(title = "Logistic Regression Predictions",
subtitle = "Predictions: 87 correct | 13 Incorrect",
fill = "Purchase",
shape = "Support",
color = "Color") +
scale_color_manual(values = cols) +
scale_shape_manual(values = shapes)
# Carga de dataset
dataset = read_csv(file = "Datasets/Social_Network_Ads.csv")
#View(dataset)
#glimpse(dataset)
dataset %>%
select(c(-1,-2)) -> dataset
# Codificacion de la variable respuesta como factor
dataset$Purchased <- factor(x = dataset$Purchased, levels = c(0,1))
# Separacion de dataset en Training y Testing
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training = subset(dataset, split == TRUE)
testing = subset(dataset, split == FALSE)
# Escalado
training[, 1:2] = scale(training[, 1:2])
testing[, 1:2] = scale(testing[, 1:2])
# Modelo
classifier <- glm(formula = Purchased ~ .,
data = training,
family = binomial)
#summary(classifier)
# Predicciones
# Probabilidades
prob_pred <- predict(object = classifier,
type = "response",
newdata = testing[, 1:2])
# Predicciones con umbral de 0.5
y_pred <- ifelse(prob_pred > 0.5, 1, 0)
testing %>%
mutate(Preds = y_pred,
Probs = prob_pred) -> modelo
modelo %>%
mutate(Correct = ifelse(Purchased == Preds, "Yes", "No")) -> modelo
#View(modelo)
# Matriz de confusion para revisar predicciones correctas
cm = table(Real = modelo$Purchased, Predict = modelo$Preds)
cm
#    Predict
#Real  0  1
#   0 57  7
#   1 10 26
sum(diag(cm))  # 83 predicciones correctas
sum(diag(apply(cm,2,rev))) # 17 predicciones incorrectas
set_testing = testing
X1_testing = seq(min(set_testing[, 1]) - 1, max(set_testing[, 1]) + 1, by = 0.01)
X2_testing = seq(min(set_testing[, 2]) - 1, max(set_testing[, 2]) + 1, by = 0.01)
grid_set_testing = expand.grid(X1_testing, X2_testing)
colnames(grid_set_testing) = c('Age', 'EstimatedSalary')
y_grid_testing = predict(object = classifier, newdata = grid_set_testing)
View(modelo)
cols <- c('Red' = 'red', 'Green' = 'green')
shapes <- c('No' = 4, 'Yes' = 1)
ggplot() +
geom_tile(data = grid_set_testing,
mapping = aes(x = Age,
y = EstimatedSalary,
fill = y_grid_testing)) +
geom_point(data = modelo,
mapping = aes(x = Age,
y = EstimatedSalary,
shape = Correct),
size = 3) +
labs(title = "Logistic Regression Predictions",
subtitle = "Predictions: 87 correct | 13 Incorrect",
fill = "Purchase",
shape = "Support",
color = "Color") +
scale_color_manual(values = cols) +
scale_shape_manual(values = shapes)
.8/.2
# Librerias
library(tidyverse)
# Dataset
dataset <- read_csv(file = "Datasets/experience_task.csv")
glimpse(dataset)
View(dataset)
summary(dataset$experience)
# Estadisticas descriptivas
#
# Distribucion de la variable experience
summary(dataset$experience)
# Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
# 4.00    9.00   18.00   16.88   24.00   32.00
#
boxplot(x = dataset$experience, title="Boxplot Experience (Months)")
hist(x = dataset$experience)
dataset %>%
group_by(success) %>%
summarise(MeanExperience = mean(experience))
dataset %>%
group_by(success) %>%
summarise(meanExperience = mean(experience))
dataset %>% table(success, experience)
table(dataset$experience, dataset$success)
table(dataset$success, dataset$experience)
plot(dataset$success, dataset$experience)
plot(dataset$experience, dataset$success)
?glm
modelo <- glm(formula = success ~ .,
data = dataset,
family = "binomial")
summary(modelo)
anova(modelo)
modelo$coefficients
modelo$residuals
modelo$fitted.values
modelo$effects
modelo$linear.predictors
modelo$boundary
library(caTools)
set.seed(123)
split = sample.split(dataset$success, SplitRatio = 0.75)
training = subset(dataset, split == TRUE)
testing = subset(dataset, split == FALSE)
modelo <- glm(formula = success ~ .,
data = training,
family = binomial)
summary(modelo)
modelo <- glm(formula = success ~ .,
data = testing,
family = binomial)
View(testing)
View(training)
modelo <- glm(formula = success ~ .,
data = dataset,
family = binomial)
summary(modelo)
anova(modelo)
modelo <- glm(formula = success ~ .,
data = training,
family = binomial)
summary(modelo)
anova(modelo)
modelo$method
modelo$R
modelo$family$link
modelo$family$family
modelo$qr$qr
modelo$iter
modelo$weights
plot(modelo)
View(modelo)
y_pred <- predict.glm(object = modelo, newdata = testing)
y_pred
y_pred <- predict.glm(object = modelo, newdata = testing, type = "response")
y_pred
y_pred <- predict.glm(object = modelo, newdata = testing[,1], type = "response")
y_pred
modelo$fitted.values
y_pred <- predict.glm(object = modelo, newdata = testing[,1])
y_pred
y_pred <- predict(object = modelo, newdata = testing[,1])
testing[,1]
y_pred
modelo$fitted.values
prob_pred <- predict(object = classifier,
type = "response",
newdata = testing[, 1:2])
prob_pred <- predict(object = modelo,
type = "response",
newdata = testing[,1])
prob_pred
y_pred <- ifelse(prob_pred > 0.8, 1, 0)
y_pred
y_pred <- ifelse(prob_pred > 0.7, 1, 0)
y_pred
y_pred
View(testing)
prob_pred
y_pred <- ifelse(prob_pred > 0.5, 1, 0)
y_pred
testing %>%
mutate(Preds = y_pred,
Probs = prob_pred) -> tm
View(tm)
tm %>%
mutate(Correct = ifelse(succsess == Preds, "Yes", "No")) -> tm
tm %>%
mutate(Correct = ifelse(success == Preds, "Yes", "No")) -> tm
# Matriz de confusion para revisar predicciones correctas
cm = table(Real = tm$succsess, Predict = tm$Preds)
# Matriz de confusion para revisar predicciones correctas
cm = table(Real = tm$success, Predict = tm$Preds)
cm
sum(diag(cm))  # 83 predicciones correctas
sum(diag(apply(cm,2,rev))) # 17 predicciones incorrectas
# Creacion del modelo
modelo <- glm(formula = success ~ .,
data = dataset,
family = binomial)
prob_pred <- predict(object = modelo,
type = "response",
newdata = dataset[,1])
y_pred <- ifelse(prob_pred > 0.5, 1, 0)
testing %>%
mutate(Preds = y_pred,
Probs = prob_pred) -> tm
tm %>%
mutate(Correct = ifelse(success == Preds, "Yes", "No")) -> tm
# Matriz de confusion para revisar predicciones correctas
cm = table(Real = tm$success, Predict = tm$Preds)
cm
sum(diag(cm))  # 5 predicciones correctas
sum(diag(apply(cm,2,rev))) # 2 predicciones incorrectas
prob_pred <- predict(object = modelo,
type = "response",
newdata = dataset[,1])
y_pred <- ifelse(prob_pred > 0.5, 1, 0)
dataset %>%
mutate(Preds = y_pred,
Probs = prob_pred) -> tm
tm %>%
mutate(Correct = ifelse(success == Preds, "Yes", "No")) -> tm
# Matriz de confusion para revisar predicciones correctas
cm = table(Real = tm$success, Predict = tm$Preds)
cm
seq(3,9,0.1)
pnorm(q = seq(3,9,0.1), mean = 6,sd = 1)
plot(x = seq(3,9,0.1),y=pnorm(q = seq(3,9,0.1), mean = 6,sd = 1))
plot(x = seq(3,9,0.1),y=pnorm(q = seq(3,9,0.1), mean = 6,sd = 1), type = "l")
# Creacion del modelo
modelo <- glm(formula = success ~ .,
data = dataset,
family = gaussian)
summary(modelo)
anova(modelo)
prob_pred <- predict(object = modelo,
type = "response",
newdata = dataset[,1])
y_pred <- ifelse(prob_pred > 0.5, 1, 0)
dataset %>%
mutate(Preds = y_pred,
Probs = prob_pred) -> tm
tm %>%
mutate(Correct = ifelse(success == Preds, "Yes", "No")) -> tm
# Matriz de confusion para revisar predicciones correctas
cm = table(Real = tm$success, Predict = tm$Preds)
cm
View(modelo)
# Creacion del modelo
modelo <- glm(formula = success ~ .,
data = dataset,
family = binomial(link = "probit"))
summary(modelo)
anova(modelo)
prob_pred <- predict(object = modelo,
type = "response",
newdata = dataset[,1])
y_pred <- ifelse(prob_pred > 0.5, 1, 0)
dataset %>%
mutate(Preds = y_pred,
Probs = prob_pred) -> tm
tm %>%
mutate(Correct = ifelse(success == Preds, "Yes", "No")) -> tm
# Matriz de confusion para revisar predicciones correctas
cm = table(Real = tm$success, Predict = tm$Preds)
cm
# Creacion del modelo
modelo <- glm(formula = success ~ .,
data = dataset,
family = binomial(link = "logit"))
summary(modelo)
anova(modelo)
prob_pred <- predict(object = modelo,
type = "response",
newdata = dataset[,1])
y_pred <- ifelse(prob_pred > 0.5, 1, 0)
dataset %>%
mutate(Preds = y_pred,
Probs = prob_pred) -> tm
tm %>%
mutate(Correct = ifelse(success == Preds, "Yes", "No")) -> tm
# Matriz de confusion para revisar predicciones correctas
cm = table(Real = tm$success, Predict = tm$Preds)
cm
(1/6)/(5/6)
1/6
tm %>% mutate(odds = Probs/(1-Probs))
modelo$coefficients
modelo$coefficients[2]
modelo$coefficients[[2]]
exp(modelo$coefficients[[2]])
ggplot(data = tm, mapping = aes(x = experience, y = success)) +
geom_point(alpha = 0.5) +
geom_smooth(method = "glm", se=F, method.args=list(family="binomial"))
ggplot(data = tm, mapping = aes(x = experience, y = success)) +
geom_point(alpha = 0.5) +
geom_smooth(method = "glm", se=F, method.args=list(family="binomial")) +
geom_line()
ggplot(data = tm, mapping = aes(x = experience, y = success)) +
geom_point(alpha = 0.5) +
geom_smooth(method = "glm", se=F, method.args=list(family="binomial")) +
geom_point()
ggplot(data = tm, mapping = aes(x = experience, y = success)) +
geom_point(alpha = 0.5) +
geom_smooth(method = "glm", se=F, method.args=list(family="binomial"))
ggplot(data = tm, mapping = aes(x = experience, y = success)) +
geom_point(alpha = 0.5) +
geom_smooth(method = "glm", se=F, method.args=list(binomial(link = "logit")))
ggplot(data = tm, mapping = aes(x = experience, y = success)) +
geom_point(alpha = 0.5) +
geom_smooth(method = "glm", se=F, method.args=list(binomial(link = "logit"))) +
geom_smooth(method = "glm", se=F, method.args=list(binomial(link = "probit")))
ggplot(data = tm, mapping = aes(x = experience, y = success)) +
geom_point(alpha = 0.5) +
geom_smooth(method = "glm", se=F, method.args=list(binomial(link = "logit"))) +
geom_smooth(method = "glm", se=F, method.args=list(binomial(link = "probit")), color ="red")
ggplot(data = tm, mapping = aes(x = experience, y = success)) +
geom_point(alpha = 0.5) +
geom_smooth(method = "glm", se=F, method.args=list(binomial(link = "logit"))) +
geom_smooth(method = "glm", se=F, method.args=list(binomial(link = "probit")),
color ="orange",
alpha=0.6)
ggplot(data = tm, mapping = aes(x = experience, y = success)) +
geom_point(alpha = 0.5) +
geom_smooth(method = "glm", se=F, method.args=list(binomial(link = "logit"))) +
geom_smooth(method = "glm", se=F, method.args=list(binomial(link = "log-log")),
color ="orange",
alpha=0.6)
ggplot(data = tm, mapping = aes(x = experience, y = success)) +
geom_point(alpha = 0.5) +
geom_smooth(method = "glm", se=F, method.args=list(binomial(link = "logit"))) +
geom_smooth(method = "glm", se=F, method.args=list(binomial(link = "loglog")),
color ="orange",
alpha=0.6)
ggplot(data = tm, mapping = aes(x = experience, y = success)) +
geom_point(alpha = 0.5) +
geom_smooth(method = "glm", se=F, method.args=list(binomial(link = "logit"))) +
geom_smooth(method = "glm", se=F, method.args=list(binomial(link = "probit")),
color ="orange",
alpha=0.6)
30/200
# Dataset
dataset <- read_csv(file = "Datasets/cupons.csv")
glimpse(dataset)
View(dataset)
# Creacion del modelo
modelo <- glm(formula = coupons.redeemed ~ number.households,
data = dataset,
family = binomial(link = "logit"))
# Creacion del modelo
modelo <- glm(formula = as.factor(coupons.redeemed) ~ number.households,
data = dataset,
family = binomial(link = "logit"))
summary(modelo)
# Creacion del modelo
modelo <- glm(formula = as.factor(prop.coup.red) ~ number.households,
data = dataset,
family = binomial(link = "logit"))
summary(modelo)
anova(modelo)
dataset$coupons.redeemed <- 1
# Creacion del modelo
modelo <- glm(formula = coupons.redeemed ~ number.households,
data = dataset,
family = binomial(link = "logit"))
summary(modelo)
anova(modelo)
