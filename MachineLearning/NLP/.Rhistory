# librerias
library(tidyverse)
# Dataset
dataset <- read_tsv(file = "Datasets/Restaurant_Reviews.tsv")
View(dataset)
sum(dataset$Liked)
n(dataset$Liked)
count(dataset$Liked)
count(as.factor(dataset$Liked))
count(dataset$Liked == 1)
?count
dataset %>% count(Liked)
install.packages("tm")
library(tidyverse)
library(NLP)
library(tm)
corpus <- VCorpus(VectorSource(dataset$Review))
# cambiar a minuscula
corpus <- tm_map(x = corpus, content_transformer(str_to_lower))
# consultar la primera linea del corpus
# corpus[[1]][1]
# Remover numeros
corpus <- tm_map(x = corpus, removeNumbers)
# Remover puntos diacriticos
corpus <- tm_map(x = corpus, removePunctuation)
corpus[[2]][1]
library(SnowballC)
library(caTools)
library(randomForest)
library(tidyverse)
library(NLP)
library(tm)
library(SnowballC)
library(caTools)
library(randomForest)
dataset <- read_tsv(file = "Datasets/Restaurant_Reviews.tsv")
# Limpieza de texto
# Corpus de datos
corpus <- VCorpus(VectorSource(dataset$Review))
# cambiar a minuscula
corpus <- tm_map(x = corpus, content_transformer(str_to_lower))
# consultar la primera linea del corpus
# corpus[[1]][1]
# Remover numeros
corpus <- tm_map(x = corpus, removeNumbers)
# Remover puntos diacriticos
corpus <- tm_map(x = corpus, removePunctuation)
# Remover palabras no esenciales
corpus <- tm_map(x = corpus, removeWords, stopwords(kind = "en"))
# Raices de verbos
corpus <- tm_map(corpus, stemDocument)
# Remover espacios en blanco
corpus <- tm_map(corpus, stripWhitespace)
corpus[[1]][1]
corpus[[567]][1]
corpus[[568]][1]
corpus[[768]][1]
# Creacion de matriz dispersa de caracteristicas
dtm <- DocumentTermMatrix(corpus)
dtm$nrow
dtm$ncol
dtm$dimnames$Docs
dtm$dimnames$Terms
# Remover palabras poco frecuentes
dtm <- removeSparseTerms(dtm, 0.999)
dtm$dimnames$Terms
# Estructura transformada a matriz
df <- as.data.frame(as.matrix(dtm))
View(df)
corpus[[23]][1]
corpus[[22]][1]
# Agregar variable respuesta
df$Liked <- dataset$Liked
# Codificacion de la variable respuesta como factor
df$Liked <- factor(df$Liked, levels = c(0, 1))
# Separacion en training y testing
set.seed(123)
split <- sample.split(df$Liked, SplitRatio = 0.8)
training <- subset(df, split == TRUE)
testing <- subset(df, split == FALSE)
classifier <- randomForest(x = training[-692],
y = training$Liked,
ntree = 10)
classifier$err.rate
classifier$type
classifier$ntree
classifier$forest$nodestatus
# Predicciones
y_pred <- predict(classifier, newdata = testing[-692])
# Matriz de Confusion
cm <- table(testing[, 692], y_pred)
cm
classifier <- randomForest(x = training[-692],
y = training$Liked,
ntree = 50)
# Predicciones
y_pred <- predict(classifier, newdata = testing[-692])
# Matriz de Confusion
cm <- table(testing[, 692], y_pred)
cm
classifier <- randomForest(x = training[-692],
y = training$Liked,
ntree = 10)
# Predicciones
y_pred <- predict(classifier, newdata = testing[-692])
# Matriz de Confusion
cm <- table(testing[, 692], y_pred)
cm
